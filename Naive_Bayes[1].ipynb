{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are all Header files needed for the naive bayes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import collections\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split # Header file to split data\n",
    "df= pd.read_csv(\"tac.csv\") #Dataset\n",
    "def dismilarity(x,y):\n",
    "    return np.sqrt(np.sum(np.square(x-y))) #euclidean distance calculation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "y=df[\"Result\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, y, test_size=0.1) #data has been split into training and testing data\n",
    "prior_lis=[]\n",
    "p=n=0\n",
    "for i in y_train: #calculation for prior\n",
    "    #print(i)\n",
    "    if(i=='positive'):\n",
    "        p+=1\n",
    "    else:\n",
    "        n+=1\n",
    "p_posi=p/len(y_train)\n",
    "p_nega=n/len(y_train) #prior calculation for matrix\n",
    "prior = {'positive' : p_posi, 'negative' : p_nega}\n",
    "unique_dic={}\n",
    "for(column_name,j)in x_train.iteritems():\n",
    "    count=len(set(j.values))                #unique values needed in the class count probability\n",
    "    #print(column_name)\n",
    "    unique_dic[column_name]=count\n",
    "#print(unique_dic)\n",
    "#print(x_test.iloc[-1][-1])\n",
    "\n",
    "p_df = x_test[x_test['Result'] == 'positive']\n",
    "n_df = x_test[x_test['Result'] == 'negative']\n",
    "\n",
    "p_count={}\n",
    "n_count={}\n",
    "column_list_df=[]\n",
    "for column in p_df:\n",
    "    p_count[column]=((p_df[column].value_counts()+1).to_dict())  #calculating probabilities in every dataset for positive values\n",
    "#print(p_count)\n",
    "n_count={}\n",
    "for column in n_df:\n",
    "    n_count[column]=((n_df[column].value_counts()+1).to_dict())\n",
    "\n",
    "cp_count={}\n",
    "p_hh={}\n",
    "cn_count={}\n",
    "for key,value in p_count.items():\n",
    "    if key!='Result':\n",
    "        for key1,value1 in value.items():\n",
    "            cp_count[key1]=value1/((p_count['Result']['positive']-1)+unique_dic[key])  #calculating conditional probabilities\n",
    "        \n",
    "        if key not in p_hh.keys():\n",
    "            p_hh.setdefault(key,{}).update(cp_count)\n",
    "\n",
    "n_hh={}\n",
    "for key,value in n_count.items():\n",
    "    if key!='Result':\n",
    "        for key1,value1 in value.items():\n",
    "            cp_count[key1]=value1/((n_count['Result']['negative']-1)+unique_dic[key]) #conditional probability for negative class\n",
    "        \n",
    "        if key not in n_hh.keys():\n",
    "            n_hh.setdefault(key,{}).update(cp_count)\n",
    "\n",
    "c_lis=[\"LT\",\"MT\",\"RT\",\"LB\",\"MM\",\"RM\",\"LB\",\"MB\",\"RB\"] #columns present in datadet\n",
    "# print(x_test.head())\n",
    "# print(p_hh)\n",
    "pred =[]\n",
    "for i in range(len(x_test)):\n",
    "    posi=1\n",
    "    nega=1\n",
    "    for j in range(0,9):\n",
    "        \n",
    "        posi=posi*p_hh[c_lis[j]][x_test.iloc[i][j]] #multiplication of prior\n",
    "        nega=nega*n_hh[c_lis[j]][x_test.iloc[i][j]]\n",
    "    n_posi=posi*p_posi\n",
    "    n_nega=nega*p_nega\n",
    "    if(n_posi>n_nega):\n",
    "        pred.append('positive')   \n",
    "    else:\n",
    "        pred.append('negative')\n",
    "se=pd.Series(pred)\n",
    "x_test['predictions'] = se.values #receiving predicted values\n",
    "#print(x_test)\n",
    "y=x_test.to_csv(r'C:\\Users\\Jagmeet Singh Sidhu\\Desktop\\data1\\predictions.csv') #creation of csv file that predicts value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP=FP=FN=TN=0 #calculation of confusion matrix\n",
    "for i in range(len(x_test)):\n",
    "    for j in range((11)):\n",
    "        #print(x_test.iloc[i][10],\" \",x_test.iloc[i][9])\n",
    "        if (x_test.iloc[i][10]==\"positive\" and x_test.iloc[i][9]==\"positive\"):\n",
    "            TP+=1\n",
    "        elif (x_test.iloc[i][10]==\"positive\" and x_test.iloc[i][9]==\"negative\"):\n",
    "            FP+=1\n",
    "        elif (x_test.iloc[i][10]==\"negative\" and x_test.iloc[i][9]==\"positive\"):\n",
    "            FN+=1\n",
    "        elif (x_test.iloc[i][10]==\"negative\" and x_test.iloc[i][9]==\"negative\"):\n",
    "            TN+=1\n",
    "#print(TP,\"\\n\",FP,\"\\n\",FN,\"\\n\",TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8194444444444444\n"
     ]
    }
   ],
   "source": [
    "sen=(TP/(TP+FN))\n",
    "print (sen) #sensitivity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n"
     ]
    }
   ],
   "source": [
    "specificity=(TN/(FP+TN))\n",
    "print(specificity)#specificity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7708333333333334\n"
     ]
    }
   ],
   "source": [
    "acc=(TN+TP)/((TP+TN+FP+FN))\n",
    "print(acc) #accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
